
---
Title: "Diabetes Readmission Prediction -Data Analysis "
author: "Amit"
date: "February 26, 2017"
output:  rmarkdown::github_document
---
```{r, echo = FALSE}
knitr::opts_chunk$set(
  fig.path = "README_figs/README-"
)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

 
The dataset used is from UCI Machine learning website and represents 10 years (1999-2008) of clinical care at 130 U.S. hospitals. It contains over 50 (33 character and 17 numeric) variables with attributes such as patient number, demographic characteristics, various type of hospital visits, length of stay, diabetic medications, number of outpatient, inpatient, emergency visits, medications administered and readmitted status. We have trained and tested a range of models to identify the best performing model. I used Decision tress, Random Forest, and Logistic Regression, to discover key factors that explain readmission are number of lab procedures, number of impatient visits, number of medications, time spent in hospital and discharge disposition id.

The results obtained by random forest and decision tree on the actual imbalanced data set are the same as previous research on this data set, as evidence towards the predictors available are not encompassing the true cause of readmission. However, I used synthetic data balancing techniques and improved model accuracy

---
```{r setup, include=FALSE}
library("Rfacebook")
require("httr")
library("httr")
require("httpuv")
# installr::updateR()
require("rjson")
library("rjson")
require("devtools")
library("devtools")
library("RColorBrewer")
# install_github('rCharts', 'ramnathv') # To produce interactive visualization, we need to install rCharts.
library(scales)  # For rendering comman separated numbers. e.g., "1,000" instead of "1000"
library(ggplot2)
library(plyr)
library(reshape2) # Used for converting data
# install.packages("SocialMediaLab")
# install.packages("stringr")
# install.packages("dplyr")
# install.packages("igraph") 
library(lubridate)
library(SocialMediaLab)
library(stringr)
library(SnowballC)
library(wordcloud)
library(dplyr, pos=99) # dplyr and igraph in high position to avoid masking plyr.
library(igraph, pos=100) 
library(MASS)
library(tm)
library(pander)

library(corrplot)
#library(rvest)      # Web scraping 
library(syuzhet)    # Sentiment package
library(dplyr)      # Wrangling
library(data.table) # Wrangling
library(zoo)        # For dragging down non-NA values to NA columns
library(ggplot2)    # Graphing
library(tidyr)
library(png)
library(grid)
library(gridExtra)
library(RCurl)
library(caret)
library(glmnet)
library(ROSE)
library(tree)
library(ROCR)
library(rpart)
library(rpart)
library(png)
library(raster)
library(rasterImage)
```
#### DIABETES READMISION PREDICTION:DATA ANALYSIS
#### Data Source- UCI Machine learning website
#### DATA INGESTION
```{r}
#binData <- getBinaryURL("https://archive.ics.uci.edu/ml/machine-learning-databases/00296/dataset_diabetes.zip", ssl.verifypeer=FALSE)
#head(binData)
#conObj <- file("dataset_diabetes.zip", open = "wb") # writing binary file
#writeBin(binData, conObj) #transfer binary data 
#close(conObj) # close connection
#files <- unzip("dataset_diabetes.zip") 
#diabetes <- read.csv(files[1], stringsAsFactors = FALSE) # file[1] = diabetic_data.csv
#names(diabetes)
#head(diabetes)
```
# data cleansing 

```{r}
#1: remove non useful columns-
#import data if data ingenstion does not work- we have shortned the title of some variables like discharge_disposition_id as discharge_id so that  decision trees are better
diabetes <- read.csv("C:/Users/Amit/Dropbox/Dataset/diabetic_data.csv")
diabetes1 <- subset(diabetes,select=-c(encounter_id, patient_nbr, examide,citoglipton,weight, payer_code, medical_spec)) 
diabetes2 <- diabetes1[diabetes1$race != "?",] # No. of observations drops by 2273
diabetes2 <- diabetes2[diabetes2$diag_1 != "?",] # No of observations drops by 21
diabetes2 <- diabetes2[diabetes2$diag_2 != "?",] # No of observations drops by 358
diabetes2 <- diabetes2[diabetes2$diag_3 != "?",] # No of observations drops by 1453
```
##### removed non useful columns
##### examide and citoglipton were not given even to a single patient hence removed and weight is missing for 97% of observations and payer code for 47% of observations

### binary representation of readmitted within 30 days
#### "0" represnts No readmisson or readmission after 30 days whereas 1 represents readmission within 30 days
```{r}
diabetes2$readmittedbin <- ifelse(diabetes2$readmitted == "<30",1,0) 
```
### To make factor of levels
```{r}
diabetes3 <- cbind(diabetes2[c(7:13,17)], lapply(diabetes2[c(1:6,14:16,18:44)],factor))
head(diabetes3)
```
### table to get frquency of different levels of readmission
```{r}
table(diabetes3$readmitted)
prop.table(table(diabetes3$readmitted))

table(diabetes3$readmittedbin)
prop.table(table(diabetes3$readmittedbin))

racewise <- table(diabetes3$readmittedbin,diabetes3$race)
racewise

genderwise <- table(diabetes3$readmittedbin,diabetes3$gender)
genderwise

agewise <- table(diabetes3$readmittedbin,diabetes3$age)
agewise

timinhoswise <- table(diabetes3$readmittedbin,diabetes3$time_in_hos)
timinhoswise
           
Number_patients <- table(diabetes3$readmitted)
plot(Number_patients,col ="lightblue", xlab = " Readmission Days ", main= " Frequency of Readmission", lwd =20,pch=18)

Number_patients_bin <- table(diabetes3$readmittedbin)
plot(Number_patients_bin,col ="lightblue", xlab = " Readmission Days ", main= " Frequency of Readmission", lwd =20,pch=18)
```
# split the data into training and testing data sets
#### We are using a sample training data as our original sample has 100,000 observations. This large data takes a long time to finish and we face issues with Rmarkdown. Hence we are using a smaller training data (20,000 observations)
```{r} 
set.seed(111)
inTrain <- createDataPartition(diabetes3$readmittedbin, p=.2, list=FALSE)
objTrain <-diabetes3[inTrain,]
objTest <- diabetes3[-inTrain,]
table(objTrain$readmittedbin)
prop.table(table(objTrain$readmittedbin))
table(objTest$readmittedbin)
prop.table(table(objTest$readmittedbin))

```
As we see, this data set contains only 11% of cases of readmission within 30 days and 89% of cases with readmission after 30 days or No readmission. This is a severely imbalanced data set.

Let us see how badly can this affect our prediction accuracy ? Let's build a model on this data. I'll be using decision tree algorithm for modeling purpose.
#Prediction with three levels of response variable
```{r}

cfit <- rpart(readmitted ~ time_in_hos + num_lab_proc + num_proc + num_medic + num_out + num_emerg + num_inpat + race + age + adm_type_id + discharge_id + adm_source_id + num_diag + max_glu_ser + A1Cresult + metformin + insulin, data = objTrain, method="class", minsplit = 20, minbucket = 5, cp = 0.001)

head(predict(cfit))

par(mar=c(1,1,0.25,1))
plot(cfit, branch = 0.4,uniform = TRUE, compress = TRUE)
text(cfit, pretty = 0)

rpart.predict <- predict(cfit, newdata = objTrain, type="class")
tail(rpart.predict)
#accuracy.meas(objTest$readmitted, rpart.predict[,2])
cf <-confusionMatrix(rpart.predict, objTrain$readmitted)
cf

#Mean error rate
mean.error.rate.rpart <- 1- cf$overall[1]
mean.error.rate.rpart
par(mar=c(3,3,3,3))
plotcp(cfit,lty = 3, col = 1)
printcp(cfit)
# The plot shows 3 branches as optimum. The CP value for 3 branches would be around 0.0014. Pruning and replotting the tree:

# Cross-validation of the tree
cfit.tree <- tree(readmitted ~ time_in_hos + num_lab_proc + num_proc + num_medic + num_out + num_emerg + num_inpat + race + age + adm_type_id + discharge_id + adm_source_id + num_diag + max_glu_ser + A1Cresult + metformin + insulin, data = objTrain, method="class")
cv.cfit.tree <- cv.tree(cfit.tree, FUN = prune.misclass)
cv.cfit.tree

prune.cfit.tree <- prune.misclass(cfit.tree, best = 4)
#plot(prune.cfit.tree)
text(prune.cfit.tree, pretty = 0)

#After pruning
cfit2 = prune(cfit, cp = 0.0014)

par(mar=c(1,1,0.25,1))
plot(cfit2, branch = 0.4,uniform = TRUE, compress = TRUE)
text(cfit2)

#Using the pruned tree to predict and pulling up the mean error rate and confusion matrix

#Prediction on test set
rpart.prune.predict <- predict(cfit2, newdata = objTest,type = "class")

cf.prune <-confusionMatrix(rpart.prune.predict,objTest$readmitted)

#Mean error rate
mean.error.rate.rpart.prune <- 1- cf.prune$overall[1]
mean.error.rate.rpart.prune
cf.prune$table

```
# Decision Tree with two class response variable
```{r}
cfit_bin <- rpart(readmittedbin ~ time_in_hos + num_lab_proc + num_proc + num_medic + num_out + num_emerg + num_inpat + race + age + adm_type_id + discharge_id + adm_source_id + num_diag + max_glu_ser + A1Cresult + metformin + insulin, data = objTrain, method="class", minsplit = 1, minbucket = 1, cp = 0.001)

par(mar=c(2,2,0.25,1))
plot(cfit_bin, branch = 0.4,uniform = TRUE, compress = TRUE)
text(cfit_bin, pretty = 0)
#How to read plotcp - http://www.wekaleamstudios.co.uk/posts/classification-trees-using-the-rpart-function/#m3mLNpeke0I
rpart.predict_bin <- predict(cfit_bin, newdata = objTrain,type="prob")

View(objTrain)
head(rpart.predict_bin)
View(rpart.predict_bin)
accuracy.meas(objTrain$readmittedbin, rpart.predict_bin[,2])

roc.curve(objTrain$readmittedbin, rpart.predict_bin[,2], plotit = T)
par =TRUE
```
AUC = 0.61 is a terribly low score. Therefore, it is necessary to balanced data before applying a machine learning algorithm. In this case, the algorithm gets biased toward the majority class and fails to map minority class. I have used the sampling techniques and try to improve this prediction accuracy. 
```{r}
str(rpart.predict_bin)
str(objTrain$readmittedbin)
#cf_bin <-confusionMatrix(rpart.predict_bin, objTrain$readmittedbin)
#cf_bin
#Mean error rate
#mean.error.rate.rpart_bin <- 1- cf_bin$overall[1]
#mean.error.rate.rpart_bin
#par(mar=c(3,3,3,3))
#plotcp(cfit_bin,lty = 3, col = 1)
#printcp(cfit_bin)
```

#The plot shows 34 branches as optimum. The CP value for 2 branches would be around 0.001. Pruning and replotting the tree:
```{r}
#After pruning
cfit2_bin = prune(cfit_bin, cp = 0.0001)

par(mar=c(.5,.5,.5,.5))
plot(cfit2_bin, branch = 0.4,uniform = TRUE, compress = TRUE)
text(cfit2_bin, pretty=0)
head(predict(cfit2_bin))
```

```{r}
#Prediction on training  set
rpart.prune.predict2_bin <- predict(cfit2_bin, newdata = objTrain,type = "class")

cf.prune_bin <-confusionMatrix(rpart.prune.predict2_bin,objTrain$readmittedbin)
cf.prune_bin
#Mean error rate
mean.error.rate.rpart.prune2 <- 1- cf.prune_bin$overall[1]
mean.error.rate.rpart.prune2
```

### over sampling
```{r}
table(objTrain$readmittedbin)
data_balanced_over <- ovun.sample(readmittedbin ~ time_in_hos + num_lab_proc + num_proc + num_medic + num_out + num_emerg + num_inpat + race + age + adm_type_id + discharge_id + adm_source_id + num_diag + max_glu_ser + A1Cresult + metformin + insulin, data = objTrain, method = "over", N = 34794)$data
table(data_balanced_over$readmittedbin)

```
### under sampling
```{r}
data_balanced_under <- ovun.sample(readmittedbin ~ time_in_hos + num_lab_proc + num_proc + num_medic + num_out + num_emerg + num_inpat + race + age + adm_type_id + discharge_id + adm_source_id + num_diag + max_glu_ser + A1Cresult + metformin + insulin, data = objTrain, method = "under", N = 4428, seed=1)$data
table(data_balanced_under$readmittedbin)

```
# Balanced sampling
#### Let us do both undersampling and oversampling on this imbalanced data. This can be achieved using method = "both". In this case, the minority class is oversampled with replacement and majority class is undersampled without replacement.
```{r}
data_balanced_both <- ovun.sample(readmittedbin ~ time_in_hos + num_lab_proc + num_proc + num_medic + num_out + num_emerg + num_inpat + race + age + adm_type_id + discharge_id + adm_source_id + num_diag + max_glu_ser + A1Cresult + metformin + insulin, data = objTrain, method = "both", N = 19610, seed=1)$data
table(data_balanced_both$readmittedbin)
```
###ROSE SYTHETIC DATA BALANCING
ROSE helps us to generate data synthetically as well. The data generated using ROSE is considered to provide better estimate of original data.
```{r}
data.rose <- ROSE(readmittedbin ~ time_in_hos + num_lab_proc + num_proc + num_medic + num_out + num_emerg + num_inpat + race + age + adm_type_id + discharge_id + adm_source_id + num_diag + max_glu_ser + A1Cresult + metformin + insulin, data = objTrain,seed=1)$data
table(data.rose$readmittedbin)

```
## build decision tree models-Rose
```{r}

cfit.rose <- rpart(readmittedbin ~ time_in_hos + num_lab_proc + num_proc + num_medic + num_out + num_emerg + num_inpat + race + age + adm_type_id + discharge_id + adm_source_id + num_diag + max_glu_ser + A1Cresult + metformin + insulin, data = data.rose)
head(data.rose)
rpart.predict.rose <- predict(cfit.rose, newdata = data.rose)
par(2,2,2,2)
#roc.curve(data.rose$readmittedbin, rpart.predict.rose[,2], col= redblue(10000), add =TRUE)
par =TRUE
```

```{r}
#Prediction on rose set
rpart.prune.predict3_bin <- predict(cfit.rose, newdata = data.rose,type = "class")

cf.prune_bin <-confusionMatrix(rpart.prune.predict3_bin,objTrain$readmittedbin)
cf.prune_bin
#Mean error rate
mean.error.rate.rpart.prune2 <- 1- cf.prune_bin$overall[1]
mean.error.rate.rpart.prune2
```
### decision tree models-over sampling
```{r}
cfit.over <- rpart(readmittedbin ~ time_in_hos + num_lab_proc + num_proc + num_medic + num_out + num_emerg + num_inpat + race + age + adm_type_id + discharge_id + adm_source_id + num_diag + max_glu_ser + A1Cresult + metformin + insulin,  data = data_balanced_over)
rpart.predict.over <- predict(cfit.over, newdata = data_balanced_over)

#plot(, colorize = TRUE)
#plot(perf2, add = TRUE, colorize = TRUE)
#roc.curve(data_balanced_over$readmittedbin, rpart.predict.over[,2], add =TRUE, col = greenred(2) )
#str(rpart.predict.over)
#confusionMatrix(data_balanced_over$readmittedbin, rpart.predict.over[,2])

```
#decision tree model-undersampling
```{r}
cfit.under <- rpart(readmittedbin ~ time_in_hos + num_lab_proc + num_proc + num_medic + num_out + num_emerg + num_inpat + race + age + adm_type_id + discharge_id + adm_source_id + num_diag + max_glu_ser + A1Cresult + metformin + insulin, data = data_balanced_under)
rpart.predict.under <- predict(cfit.over, newdata = data_balanced_under)
par(new=TRUE)
#roc.curve(data_balanced_under$readmittedbin, rpart.predict.under[,2], add =TRUE, col = bluered(2))
```
#decision tree model-both under and over sampling
```{r}
cfit.both <- rpart(readmittedbin ~ time_in_hos + num_lab_proc + num_proc + num_medic + num_out + num_emerg + num_inpat + race + age + adm_type_id + discharge_id + adm_source_id + num_diag + max_glu_ser + A1Cresult + metformin + insulin, data = data_balanced_both)
rpart.predict.both <- predict(cfit.both, newdata = data_balanced_both)
#roc.curve(data_balanced_both$readmittedbin, rpart.predict.both[,2], add =TRUE, col = redblue(5))

# ROC curve comparison
img1 <-  rasterGrob(as.raster(readPNG("C:/Users/Amit/Desktop/DA6813/Project/Final/ROC curve comparison.png")), interpolate = FALSE)
#img1
grid.arrange(img1,ncol = 1)
```

# Analyze the data using random forests. Report the mean error rate and the confusion matrix.
```{r}
library(randomForest)
rf.diabetes_bin <- randomForest(readmittedbin ~ time_in_hos + num_lab_proc + num_proc + num_medic + num_out + num_emerg + num_inpat + race + age + adm_type_id + discharge_id + adm_source_id + num_diag + max_glu_ser + A1Cresult + metformin + insulin, data = objTrain,importance=TRUE)
rf.diabetes_bin
rf.predict_bin <- predict(rf.diabetes_bin,newdata =objTest)

#Plotting the errors from Random Forest model:
par(mar=c(3,3,3,3))
plot(rf.diabetes_bin, type="l")
varImpPlot(rf.diabetes_bin,main = "Important Variables")
importance(rf.diabetes_bin)

# Confusion Matrix and the mean error rate:

rf.cm_bin <- confusionMatrix(rf.predict_bin,objTest$readmittedbin)
rf.cm_bin$table
#Mean error rate
mean.error.rate.rf <- (1- rf.cm_bin$overall[1])
mean.error.rate.rf
```
Random on three class response variable
```{r}
library(randomForest)
rf.diabetes <- randomForest(readmitted ~ time_in_hos + num_lab_proc + num_proc + num_medic + num_out + num_emerg + num_inpat + race + age + adm_type_id + discharge_id + adm_source_id + num_diag + max_glu_ser + A1Cresult + metformin + insulin, data = objTrain,importance=TRUE)
rf.diabetes
rf.predict <- predict(rf.diabetes,newdata =objTest)

#Plotting the errors from Random Forest model:
par(mar=c(3,3,3,3))
plot(rf.diabetes, type="l")
varImpPlot(rf.diabetes,main = "Important Variables")
importance(rf.diabetes)

# Confusion Matrix and the mean error rate:

rf.cm <- confusionMatrix(rf.predict,objTest$readmitted)
rf.cm$table
#Mean error rate
mean.error.rate.rf <- (1- rf.cm$overall[1])
# This gives error rate
mean.error.rate.rf
```
### Post Synthetic balancing, Type II Error decrease from 94% to 45%

###Gradient boosted decision tree (gbdt) to analyze the data.Report the mean error rate and the confusion matrix. Using gbm package in R.
###### Choke for the GBM was compute time.
```{r}
#library(gbm)
#gbm.diabetes_bin <- gbm(readmittedbin ~ time_in_hos + num_lab_proc + num_proc + num_medic + num_out + num_emerg + num_inpat + race + age + adm_type_id + discharge_id + adm_source_id + num_diag + max_glu_ser + A1Cresult + metformin + insulin, data = objTrain, distribution = "bernoulli",n.trees =100,interaction.depth = 4, shrinkage = 0.005)
# Most important variables:
#par(mar=c(2,2,2,2))
#gbm.diabetes_bin

#par(mar=c(4,4,4,4))
#summary(gbm.diabetes_bin, xlim =0.1, ylim= 2)
```

```{r}
#gbm.yhat <- predict(gbm.diabetes_bin,newdata = objTrain, n.trees = 200)
#head(gbm.yhat)
#gbm.yhat1 <- ifelse(gbm.yhat < 0.385,0,1)

#library(caret)
#gbm.cm <- confusionMatrix(gbm.yhat,objTest$readmittedbin)

#Mean error rate
#mean.error.rate.gbm <- 1- gbm.cm$overall[1]
#mean.error.rate.gbm
```


